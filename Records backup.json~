{u'publisher': u'Wiley', u'x_depts': u'//*[@class="article-header__authors-item"]', u'x_title': u'string(//*[@class="article-header__title"])', u'x_person': u'string(.//*[@class="article-header__authors-name"])', u'x_abstract': u'string(//*[@id="abstract"]/div/p)', u'x_people': u'//*[@class="article-header__authors-item"]', u'pub_website': u'onlinelibrary.wiley.com', u'x_date': u'string(//time[@id="first-published-date"])', u'name_con': u'\npex2 = []\nfor p in pex:\n    name = ""\n    p = re.sub(r"\\s+", u" ", p, flags=re.UNICODE)\n    p = re.sub(\',\',u\'\',p)\n    words = p.split(" ")\n    if u\'Dr.\' in words:\n        words.remove(u\'Dr.\')\n    for w in words[:-1]:\n        if not(w==u\'\'):\n            name+=w[0]\n    name+=u" "+words[-1]\n    pex2.append(name)\npex=pex2', u'x_dept': u'string(.//*[@class="article-header__authors-item-aff-addr"])', u'_id': ObjectId('564f15193087112618056479'), u'date_con': u"\ndate = datetime.strptime(date,'%d %B %Y')"}
{u'publisher': u'Wiley', u'x_depts': u'//*[@id="authorsAffiliations"]/li', u'x_title': u'string(//*[@class="articleTitle"])', u'x_person': u'text()', u'x_abstract': u'string(//*[@id="abstract"]/div[@class="para"])', u'x_people': u'//*[@id="authors"]/li', u'pub_website': u'onlinelibrary.wiley.com', u'x_date': u'string(//p[@id="publishedOnlineDate"])', u'name_con': u'\npex2 = []\npexl=[]\nfor p in pex:\n    if type(p)==list:\n        pexl+=p\n    else:\n        pexl.append(p)\nfor p in pexl:\n    name = ""\n    p = re.sub(r"\\s+", u" ", p, flags=re.UNICODE)\n    p = re.sub(\',\',u\'\',p)\n    p = re.sub(\' and\',\'\',p )\n    words = p.split(" ")\n    if u\'Dr.\' in words:\n        words.remove(u\'Dr.\')\n    for w in words[:-1]:\n        if not(w==u\'\'):\n            name+=w[0]\n    name+=u" "+words[-1]\n    pex2.append(name)\npex=filter(lambda x: x!=u\' \',pex2)\n', u'x_dept': u'p/text()', u'_id': ObjectId('564f1519308711261805647a'), u'date_con': u"\ndate = datetime.strptime(u' '.join(date.split(' ')[-3:]),'%d %b %Y')\n        "}
{u'publisher': u'American Physical Society', u'x_depts': u'//section[@class="article authors open"]/div/ul[@class="no-bullet"]', u'x_title': u'//div[@id="title"]/descendant::h3/text()', u'x_person': u'*[1]/text()', u'x_abstract': u'//meta[@name="description"]/@content', u'x_people': u'//section[@class="article authors open"]/div/p', u'pub_website': u'journals.aps.org', u'x_date': u'//ul[@class="inline-list pub-dates"]/li/text()', u'name_con': u'\npex2 = []\nfor p in pex:\n    name = ""\n    p = re.sub(r"\\s+", u" ", p, flags=re.UNICODE)\n    p = re.sub(\',\',u\'\',p)\n    words = p.split(" ")\n    if words[0] in [u\'Dr.\']:\n        words.remove(words[0])\n    for w in words[:-1]:\n        name+=w[0]\n    name+=u" "+words[-1]\n    pex2.append(name)\npex=pex2', u'x_dept': u'li/text()', u'_id': ObjectId('564f1519308711261805647c'), u'date_con': u"\nsp = date.split(' ')\ndate = datetime.strptime(' '.join(sp[1:]),'%d %B %Y')"}
{u'publisher': u'Springer', u'x_depts': u'//ul[@class="AuthorNames"]/li', u'x_title': u'//*[@class="ArticleTitle"]/text()', u'x_person': u'*/span[@class="AuthorName"]/text()', u'x_abstract': u'string(//*[@id="Abs1"]/p)', u'x_people': u'//ul[@class="AuthorNames"]/li', u'pub_website': u'link.springer.com', u'x_date': u'//*[@class="ArticleCitation_Year"]/time/text()', u'name_con': u'\npex2 = []\nfor p in [k for k in pex if type(k)==unicode]:\n    name = ""\n    p = re.sub(r"\\s+", u" ", p, flags=re.UNICODE)\n    p = re.sub(\',\',u\'\',p)\n    words = p.split(" ")\n    if words[0] in [u\'Dr.\']:\n        words.remove(words[0])\n    for w in words[:-1]:\n        name+=w[0]\n    name+=u" "+words[-1]\n    pex2.append(name)\npex=pex2', u'x_dept': u'descendant::span[@class="AuthorsName_affiliation"]/span/text()', u'_id': ObjectId('564f1519308711261805647e'), u'date_con': u"\nsp = date.split(' ')\ndate = datetime.strptime(date,'%B %Y')"}
{u'publisher': u'ScienceDirect', u'x_depts': u'//ul[@class="affiliation authAffil"]/li', u'x_title': u'//*[@class="svTitle"]/text()', u'x_person': u'*[@class="authorName svAuthor"]/text()', u'x_abstract': u'string(//*[@class="abstract svAbstract "])', u'x_people': u'//ul[@class="authorGroup noCollab svAuthor"]/li', u'pub_website': u'www.sciencedirect.com', u'x_date': u'//dl[@class="articleDates"]/dd/text()', u'name_con': u'\npex2 = []\nfor p in pex:\n    name = ""\n    p = re.sub(r"\\s+", u" ", p, flags=re.UNICODE)\n    p = re.sub(\',\',u\'\',p)\n    words = p.split(" ")\n    if words[0] in [u\'Dr.\']:\n        words.remove(words[0])\n    for w in words[:-1]:\n        name+=w[0]\n    name+=u" "+words[-1]\n    pex2.append(name)\npex=pex2', u'x_dept': u'span/text()', u'_id': ObjectId('564f1519308711261805647f'), u'date_con': u'\nsp = date.split(\' \')\ndate = datetime.strptime(" ".join(sp[-3:]),\'%d %B %Y\')'}
{u'publisher': u'International Union of Crystallography', u'x_depts': u'//none-here', u'x_title': u'string(//*[@class="ica_title"])', u'x_person': u'string(.)', u'x_abstract': u'string(//*[@class="ica_abstract"])', u'x_people': u'//*[@class="ica_authors"]/a', u'pub_website': u'scripts.iucr.org', u'x_date': u'//div[@class="ica_header"]/span[2]/text()', u'name_con': u'\npex2 = []\nfor p in pex:\n    name = ""\n    p = re.sub(r"\\s+", u" ", p, flags=re.UNICODE)\n    p = re.sub(\',\',u\'\',p)\n    words = p.split(" ")\n    if words[0] in [u\'Dr.\']:\n        words.remove(words[0])\n    for w in words[:-1]:\n        name+=w[0]\n    name+=u" "+words[-1]\n    pex2.append(name)\npex=pex2', u'x_dept': u'//none-here', u'_id': ObjectId('564f15193087112618056480'), u'date_con': u"\ndate = datetime.strptime(date[2:6],'%Y')"}
{u'publisher': u'scientific.net', u'x_depts': u'//none-here', u'x_title': u'//div[@class="paper-title"]/div[@class="paper-name"]/text()', u'x_person': u'string(.)', u'x_abstract': u'//div[@class="abstract"]/p/text()', u'x_people': u'//div[text()="\r\n                                        Authors\r\n                                    "]/following-sibling::div/a', u'pub_website': u'www.scientific.net', u'x_date': u'//div[text()="\r\n                                        Online since\r\n                                    "]/following-sibling::div/text()', u'name_con': u'\npex2 = []\nfor p in pex:\n    name = ""\n    p = re.sub(r"\\s+", u" ", p, flags=re.UNICODE)\n    p = re.sub(\',\',u\'\',p)\n    words = p.split(" ")\n    if words[0] in [u\'Dr.\']:\n        words.remove(words[0])\n    for w in words[:-1]:\n        name+=w[0]\n    name+=u" "+words[-1]\n    pex2.append(name)\npex=pex2', u'x_dept': u'//none-here', u'_id': ObjectId('564f15193087112618056481'), u'date_con': u"\ndate = datetime.strptime(date.strip(),'%B %Y')"}
{u'publisher': u'jstage', u'x_depts': u'//*[contains(@class,"affiliation")]', u'x_title': u'string(//*[contains(@class,"mod-article-heading")])', u'x_person': u'text()', u'x_abstract': u'string(//*[contains(@class,"mod-section")]/p)', u'x_people': u'//*[contains(@class,"author")]/a', u'pub_website': u'www.jstage.jst.go.jp', u'x_date': u'string(//*[contains(@class,"date")])', u'name_con': u'\npex2 = []\nfor p in pex:\n    name = ""\n    p = re.sub(r"\\s+", u" ", p, flags=re.UNICODE)\n    p = re.sub(\',\',u\'\',p)\n    words = p.split(" ")\n    if words[0] in [u\'Dr.\']:\n        words.remove(words[0])\n    for w in words[:-1]:\n        name+=w[0]\n    name+=u" "+words[-1]\n    pex2.append(name)\npex=pex2', u'x_dept': u'text()', u'_id': ObjectId('564f15193087112618056482'), u'date_con': u'\nds = re.sub("[^0-9]", "", date)\ndates = [datetime.strptime(ds[i:i+8],\'%Y%m%d\') for i in range(0,len(ds),8)]\ndate = min(dates)'}
{u'publisher': u'iop', u'x_depts': u'//div[@class="wd-jnl-art-author-affiliations"]/p', u'x_title': u'string(//*[@class="wd-jnl-art-title"])', u'x_person': u'span[@itemprop="name"]/text()', u'x_abstract': u'string(//div[contains(@class,"wd-jnl-art-abstract")]/p)', u'x_people': u'//span[@data-authors]/span', u'pub_website': u'iopscience.iop.org', u'x_date': u'//div[contains(@class,"wd-jnl-art-dates")]/p/text()', u'name_con': u'\npex2 = []\nfor p in pex:\n    name = ""\n    p = re.sub(r"\\s+", u" ", p, flags=re.UNICODE)\n    p = re.sub(\',\',u\'\',p)\n    words = p.split(" ")\n    words = filter(lambda x: not(x==u\'\'),words)\n    if words[0] in [u\'Dr.\']:\n        words.remove(words[0])\n    for w in words[:-1]:\n        name+=w[0]\n    name+=u" "+words[-1]\n    pex2.append(name)\npex=pex2', u'x_dept': u'text()', u'_id': ObjectId('564f15193087112618056484'), u'date_con': u"\nd= date.strip()\ndate = datetime.strptime(' '.join(d.split(u' ')[-3:]),'%d %B %Y')"}
{u'publisher': u'RoyalSociety', u'x_depts': u'//span[@class="nlm-aff"]', u'x_title': u'//*[@id="page-title"]/text()', u'x_person': u'string(.)', u'x_abstract': u'//*[@id="abstract-1"]/p/text()', u'x_people': u'//span[@class="highwire-citation-authors"]/span', u'pub_website': u'rsif.royalsocietypublishing.org', u'x_date': u'//span[contains(@class,"highwire-cite-metadata-date")]/text()', u'name_con': u'\npex2 = []\nfor p in pex:\n    name = ""\n    p = re.sub(r"\\s+", u" ", p, flags=re.UNICODE)\n    p = re.sub(\',\',u\'\',p)\n    words = p.split(" ")\n    words = filter(lambda x: not(x==u\'\'),words)\n    if words[0] in [u\'Dr.\']:\n        words.remove(words[0])\n    for w in words[:-1]:\n        name+=w[0]\n    name+=u" "+words[-1]\n    pex2.append(name)\npex=pex2', u'x_dept': u'string(.)', u'_id': ObjectId('564f15193087112618056485'), u'date_con': u'\ndate=datetime.strptime(\' \'.join(date.split(u\' \')[-3:]),"%d %B %Y")'}
{u'publisher': u'RoyalSociety', u'x_depts': u'//span[@class="nlm-aff"]', u'x_title': u'//*[@id="page-title"]/text()', u'x_person': u'string(.)', u'x_abstract': u'//*[@id="abstract-1"]/p/text()', u'x_people': u'//span[@class="highwire-citation-authors"]/span', u'pub_website': u'rspa.royalsocietypublishing.org', u'x_date': u'//span[contains(@class,"highwire-cite-metadata-date")]/text()', u'name_con': u'\npex2 = []\nfor p in pex:\n    name = ""\n    p = re.sub(r"\\s+", u" ", p, flags=re.UNICODE)\n    p = re.sub(\',\',u\'\',p)\n    words = p.split(" ")\n    words = filter(lambda x: not(x==u\'\'),words)\n    if words[0] in [u\'Dr.\']:\n        words.remove(words[0])\n    for w in words[:-1]:\n        name+=w[0]\n    name+=u" "+words[-1]\n    pex2.append(name)\npex=pex2', u'x_dept': u'string(.)', u'_id': ObjectId('564f15193087112618056486'), u'date_con': u'\ndate=datetime.strptime(\' \'.join(date.split(u\' \')[-3:]),"%d %B %Y")'}
{u'publisher': u'Scitation', u'x_depts': u'//div[contains(@class,"affiliations")]/a', u'x_title': u'string(//*[@class="title-with-crossmark"])', u'x_person': u'text()', u'x_abstract': u'string(//*[contains(@class,"abstract ")]/descendant::*[@class="articleabstract"]/p[2])', u'x_people': u'//span[contains(@class,"authors")]/a', u'pub_website': u'scitation.aip.org', u'x_date': u'//div[contains(@class,"itemCitation")]/span[3]/text()', u'name_con': u'\npex2 = []\nfor p in pex:\n    name = ""\n    p = re.sub(r"\\s+", u" ", p, flags=re.UNICODE)\n    p = re.sub(\',\',u\'\',p)\n    words = p.split(" ")\n    words = filter(lambda x: not(x==u\'\'),words)\n    if words[0] in [u\'Dr.\']:\n        words.remove(words[0])\n    for w in words[:-1]:\n        name+=w[0]\n    name+=u" "+words[-1]\n    pex2.append(name)\npex=pex2', u'x_dept': u'text()', u'_id': ObjectId('564f15193087112618056487'), u'date_con': u'\nd = date[:-1].split(u" ")\ndate=datetime.strptime(u\' \'.join(d[2:4] + [d[-1]]),"%b %d %Y")'}
{u'publisher': u'Nature', u'x_depts': u'//ol[contains(@class,"affiliations")]/li', u'x_title': u'//*[@class="article-heading"]/text()', u'x_person': u'a[@class="name"]/span/text()', u'x_abstract': u'string(//*[@id="abstract"]/div/p)', u'x_people': u'//*[contains(@class,"authors citation-authors")]/li', u'pub_website': u'www.nature.com', u'x_date': u'//*[contains(@class,"citation dates")]/dd[1]/time/text()', u'name_con': u'\npex2 = []\nfor p in [k for k in pex if type(k)==unicode]:\n    name = ""\n    p = re.sub(r"\\s+", u" ", p, flags=re.UNICODE)\n    p = re.sub(\',\',u\'\',p)\n    words = p.split(" ")\n    if words[0] in [u\'Dr.\']:\n        words.remove(words[0])\n    for w in words[:-1]:\n        name+=w[0]\n    name+=u" "+words[-1]\n    pex2.append(name)\npex=pex2', u'x_dept': u'h3/text()', u'_id': ObjectId('564f15193087112618056488'), u'date_con': u'\ndate=datetime.strptime(date.strip(),"%d %B %Y")'}
{u'publisher': u'degruyter', u'x_depts': u'//*[contains(@class,"NLM_affiliations")]/p', u'x_title': u'string(//*[@class="entryTitle"])', u'x_person': u'./text()', u'x_abstract': u'string(//*[@class="articleBody_abstract"]/p)', u'x_people': u'//*[@class="contributors"]/descendant-or-self::*', u'pub_website': u'www.degruyter.com', u'x_date': u'//*[contains(@class,"pubHistory")]/dl[1]/dd/text()', u'name_con': u'\npex2=[]\nfor p in pex:\n    if type(p)==list:\n        for p1 in p:\n            if (len(p1.strip())>3): \n                pex2.append(p1.strip())\n    elif p==[]:\n        pass\n    else:\n        if len(p.strip())>3: \n            pex2.append(p.strip())\npex3=[]\nfor p in pex2:\n    name = ""\n    p = re.sub(r"\\s+", u" ", p, flags=re.UNICODE)\n    p = re.sub(\',\',u\'\',p)\n    p = re.sub(\'/\',u\'\',p)\n    words = p.split(" ")\n    words = filter(lambda x: not(x==u\'\'),words)\n    if words[0] in [u\'Dr.\']:\n        words.remove(words[0])\n    for w in words[:-1]:\n        name+=w[0]\n    name+=u" "+words[-1]\n    pex3.append(name)\npex=pex3', u'x_dept': u'text()', u'_id': ObjectId('564f15193087112618056489'), u'date_con': u'date=datetime.strptime(date,"%Y-%m-%d")'}
{u'publisher': u'rsc', u'x_depts': u'//div[@class="show_affiliation_section"]/div[position()>2]', u'x_title': u'string(//div[@class="article_chemsoc_txt_s13"])', u'x_person': u'a/text()', u'x_abstract': u'string(//div[@class="abstract_new"])', u'x_date_con': u'try:\n    d = [i.strip() for i in date.strip().split(\' \')]\n    p = filter(lambda x: not(x==u\'\'),d)\n    date = u\' \'.join(p[-3:])\n    date = datetime.strptime(date,\'%d %b %Y\')\nexcept:\n    d=response.xpath(\'//div[@class="peptide_middle"]/div[3]/text()\').extract()[1]\n    date = datetime.strptime(d.split(\',\')[1],\' %Y\')', u'x_people': u'//div[@class="peptide_middle"]/div[1]/span', u'pub_website': u'pubs.rsc.org', u'x_date': u'//div[@class="peptide_middle"]/span[last()]/text()[1]', u'name_con': u'\npex2 = []\nfor p in [k for k in pex if type(k)==unicode]:\n    name = ""\n    p = re.sub(r"\\s+", u" ", p, flags=re.UNICODE)\n    p = re.sub(\',\',u\'\',p)\n    words = p.split(" ")\n    if u\'Dr.\' in words:\n        words.remove(u\'Dr.\')\n    for w in words[:-1]:\n        if not(w==u\'\'):\n            name+=w[0]\n    name+=u" "+words[-1]\n    pex2.append(name)\npex=pex2', u'x_dept': u'div[2]/text()', u'_id': ObjectId('564f15193087112618056483'), u'date_con': u'try:\n    d = [i.strip() for i in date.strip().split(\' \')]\n    p = filter(lambda x: not(x==u\'\'),d)\n    date = u\' \'.join(p[-3:])\n    date = datetime.strptime(date,\'%d %b %Y\')\nexcept:\n    d=response.xpath(\'//div[@class="peptide_middle"]/div[3]/text()\').extract()[1]\n    date = datetime.strptime(d.split(\',\')[1],\' %Y\')'}
{u'publisher': u'Springer', u'x_depts': u'//ul[@class="AuthorNames"]/li', u'x_title': u'//*[@class="ArticleTitle"]/text()', u'x_person': u'*/span[@class="AuthorName"]/text()', u'x_abstract': u'string(//*[@id="Abs1"]/p)', u'x_people': u'//ul[@class="AuthorNames"]/li', u'pub_website': u'link.springer.com', u'x_date': u'//*[@class="ArticleCitation_Year"]/time/text()', u'name_con': u'\npex2 = []\nfor p in [k for k in pex if type(k)==unicode]:\n    name = ""\n    p = re.sub(r"\\s+", u" ", p, flags=re.UNICODE)\n    p = re.sub(\',\',u\'\',p)\n    words = p.split(" ")\n    if words[0] in [u\'Dr.\']:\n        words.remove(words[0])\n    for w in words[:-1]:\n        name+=w[0]\n    name+=u" "+words[-1]\n    pex2.append(name)\npex=pex2', u'x_dept': u'descendant::span[@class="AuthorsName_affiliation"]/span/text()', u'_id': ObjectId('564f1519308711261805647d'), u'date_con': u"\nsp = date.split(' ')\ndate = datetime.strptime(date,'%d %B %Y')"}
{u'publisher': u'Nature', u'x_depts': u'//*[@class="affiliations"]/div', u'x_title': u'string(//*[@id="atl"])', u'x_person': u'text()', u'x_abstract': u'string(//*[@id="abs"]/p)', u'x_people': u'//*[@id="aug"]', u'pub_website': u'www.nature.com', u'x_date': u'//*[@id="cite"]/text()[3]', u'name_con': u'\npex = [i.strip() for i  in pex[0].strip().replace(\'&\',\',\').split(\',\')]\npex2 = []\nfor p in [k for k in pex if type(k)==unicode]:\n    name = ""\n    p = re.sub(r"\\s+", u" ", p, flags=re.UNICODE)\n    p = re.sub(\',\',u\'\',p)\n    words = p.split(" ")\n    if words[0] in [u\'Dr.\']:\n        words.remove(words[0])\n    for w in words[:-1]:\n        name+=w[0]\n    name+=u" "+words[-1]\n    pex2.append(name)\npex=pex2', u'x_dept': u'string(.)', u'_id': ObjectId('565c606a3087111144a237b9'), u'date_con': u"\nsp = date.split()\nif len(sp)==4:\n    date = datetime.strptime(' '.join(sp[-3:-1]),'%B %Y')\nelse:\n    date = datetime.strptime(' '.join(sp[-4:-1]),'%d %B %Y')"}
{u'publisher': u'Springer', u'x_depts': u'//ul[@class="AuthorNames"]/li', u'x_title': u'//*[@class="ChapterTitle"]/text()', u'x_person': u'*/span[@class="AuthorName"]/text()', u'x_abstract': u'string(//*[@class="Abstract"]/p)', u'x_people': u'//ul[@class="AuthorNames"]/li', u'pub_website': u'link.springer.com', u'x_date': u'//*[@class="version-date"]/time[1]/text()', u'name_con': u'\npex2 = []\nfor p in [k for k in pex if type(k)==unicode]:\n    name = ""\n    p = re.sub(r"\\s+", u" ", p, flags=re.UNICODE)\n    p = re.sub(\',\',u\'\',p)\n    words = p.split(" ")\n    if words[0] in [u\'Dr.\']:\n        words.remove(words[0])\n    for w in words[:-1]:\n        name+=w[0]\n    name+=u" "+words[-1]\n    pex2.append(name)\npex=pex2', u'x_dept': u'descendant::span[@class="AuthorsName_affiliation"]/span/text()', u'_id': ObjectId('565c673d3087111144a237ba'), u'date_con': u"\ntry:\n    date = datetime.strptime(date,'%d %B %Y')\nexcept:\n    date = datetime.strptime(date,'%d %B %Y')\n    "}
{u'publisher': u'Nature', u'x_depts': u'//div[contains(@id,"popup-auth")]', u'x_title': u'//*[@itemprop="name headline"]/text()', u'x_person': u'a/span/text()', u'x_abstract': u'string(//*[@id="abstract-content"]/p)', u'x_people': u'//*[contains(@class,"list-authors")]/li', u'pub_website': u'www.nature.com', u'x_date': u'//time/text()', u'name_con': u'\npex2 = []\nfor p in [k for k in pex if type(k)==unicode]:\n    name = ""\n    p = re.sub(r"\\s+", u" ", p, flags=re.UNICODE)\n    p = re.sub(\',\',u\'\',p)\n    words = p.split(" ")\n    if words[0] in [u\'Dr.\']:\n        words.remove(words[0])\n    for w in words[:-1]:\n        name+=w[0]\n    name+=u" "+words[-1]\n    pex2.append(name)\npex=pex2', u'x_dept': u'section/ul/li[1]/text()', u'_id': ObjectId('565c7b403087111144a237bb'), u'date_con': u'\ndate=datetime.strptime(date.strip(),"%d %B %Y")'}
{u'publisher': u'Nature', u'x_depts': u'//*[@class="affiliations"]/div', u'x_title': u'string(//*[@id="atl"])', u'x_person': u'text()', u'x_abstract': u'string(//*[@class="lead"])', u'x_people': u'//*[@id="aug"]', u'pub_website': u'www.nature.com', u'x_date': u'//*[@id="cite"]/text()[4]', u'name_con': u'\npex2 = []\nfor p in [k.replace(\'&\',\',\').replace(\',\',\'\').strip() for k in pex[0] if type(k)==unicode]:\n    name = ""\n    p = re.sub(r"\\s+", u" ", p, flags=re.UNICODE)\n    p = re.sub(\',\',u\'\',p)\n    words = p.split(" ")\n    if words[0] in [u\'Dr.\']:\n        words.remove(words[0])\n    for w in words[:-1]:\n        name+=w[0]\n    name+=u" "+words[-1]\n    pex2.append(name)\npex=pex2', u'x_dept': u'string(.)', u'_id': ObjectId('565c857e3087111144a237bc'), u'date_con': u"\nsp = date.split()\nif len(sp)==4:\n    date = datetime.strptime(' '.join(sp[-3:-1]),'%B %Y')\nelse:\n    date = datetime.strptime(' '.join(sp[-4:-1]),'%d %B %Y')"}
{u'publisher': u'ACS', u'x_depts': u'//*[@class="affiliations"]/div', u'x_title': u'string(//*[@class="articleTitle"])', u'x_person': u'string(span[1])', u'x_abstract': u'string(//*[@id="abstractBox"])', u'x_people': u'//*[@id="authors"]/span', u'pub_website': u'pubs.acs.org', u'x_date': u'string(//*[@id="pubDate"])', u'name_con': u'\npex2 = []\nfor p in pex:\n    name = ""\n    p = re.sub(r"\\s+", u" ", p, flags=re.UNICODE)\n    p = re.sub(u\' and$\',u\'\',p)\n    p = re.sub(\',\',u\'\',p).replace(\'*\',\'\').strip()\n    words = p.split(" ")\n    if words[0] in [u\'Dr.\']:\n        words.remove(words[0])\n    for w in words[:-1]:\n        name+=w[0]\n    name+=u" "+words[-1]\n    pex2.append(name)\npex=pex2', u'x_dept': u'string(.)', u'_id': ObjectId('564f1519308711261805647b'), u'date_con': u"\nsp = date.split()\nif len(sp)==4:\n    date = datetime.strptime(' '.join(sp[-2:]),'%B %Y')\nelse:\n    date = datetime.strptime(' '.join([sp[-3]]+[sp[-2][:-1]]+[sp[-1]]),'%B %d %Y')"}
{u'publisher': u'rsc', u'x_depts': u'//*[@class="affiliations"]/div', u'x_title': u'string(//*[@class="sub_title"])', u'x_person': u'text()', u'x_abstract': u'string(//*[@id="Description"])', u'x_people': u'//*[@class="peptide_text_s4"]', u'pub_website': u'pubs.rsc.org', u'x_date': u'string(//*[@class="peptide_text_s4"])', u'name_con': u'\npex1=pex[0][0].strip().replace(\'*\',\'\').replace(\' and \',\',\').split(\',\')\nfor p in [k for k in pex1 if type(k)==unicode]:\n    name = ""\n    p = re.sub(r"\\s+", u" ", p, flags=re.UNICODE)\n    p = re.sub(\',\',u\'\',p)\n    words = p.split(" ")\n    if u\'Dr.\' in words:\n        words.remove(u\'Dr.\')\n    for w in words[:-1]:\n        if not(w==u\'\'):\n            name+=w[0]\n    name+=u" "+words[-1]\n    pex2.append(name)\npex=pex2', u'x_dept': u'string(.)', u'_id': ObjectId('565c92ad3087111144a237bd'), u'date_con': u'\nd=[g.strip() for g in date.split("\\r\\n") if not(g.strip()==u\'\')][2]\ndate = datetime.strptime(d,\'%d %b %Y\')'}

